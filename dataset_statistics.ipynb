{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-03-20T00:08:21.083257Z",
     "end_time": "2024-03-20T00:08:21.288865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load processed dataset...\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "import os.path as osp\n",
    "from dataset import LiteralLinkPredDataset\n",
    "import torch\n",
    "\n",
    "DATASET = \"Synthetic\"\n",
    "\n",
    "if not osp.isfile(f'data/{DATASET}/processed.pt'):\n",
    "    print('Process dataset...')\n",
    "    dataset = LiteralLinkPredDataset(f'data/{DATASET}')\n",
    "    torch.save(dataset, f'data/{DATASET}/processed.pt')\n",
    "print('Load processed dataset...')\n",
    "dataset = torch.load(f'data/{DATASET}/processed.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training triples: 275270\n",
      "Number of validation triples: 17535\n",
      "Number of test triples: 23166\n"
     ]
    }
   ],
   "source": [
    "# Get number of training, validation and test triples\n",
    "print(f\"Number of training triples: {len(dataset.df_triples_train)}\")\n",
    "print(f\"Number of validation triples: {len(dataset.df_triples_val)}\")\n",
    "print(f\"Number of test triples: {len(dataset.df_triples_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T00:08:21.292484Z",
     "end_time": "2024-03-20T00:08:21.295346Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical literals that have 0 as value: 0\n",
      "Out of 14505 numerical literals => 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Get number of numerical literals that have 0 as value\n",
    "print(f\"Number of numerical literals that have 0 as value: {dataset.df_literals_num[dataset.df_literals_num[2] == 0].shape[0]}\")\n",
    "print(f\"Out of {dataset.df_literals_num.shape[0]} numerical literals => {dataset.df_literals_num[dataset.df_literals_num[2] == 0].shape[0] / dataset.df_literals_num.shape[0] * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T00:08:21.295622Z",
     "end_time": "2024-03-20T00:08:21.303311Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical literals that have 0 as value: 2486\n",
      "Out of 148707 numerical literals => 1.67%\n",
      "Index([  1551,   1768,   2007,   2052,   2178,   2297,   2961,   3156,   3570,\n",
      "         3591,\n",
      "       ...\n",
      "       148200, 148223, 148265, 148292, 148300, 148354, 148356, 148357, 148380,\n",
      "       148633],\n",
      "      dtype='int64', length=2486)\n"
     ]
    }
   ],
   "source": [
    "# Load the LitWD48k numerical literals\n",
    "import pandas as pd\n",
    "litwd48k_num_lits = pd.read_csv('data/LitWD48k/numerical_literals_decimal.txt', sep='\\t', header=None)\n",
    "print(f\"Number of numerical literals that have 0 as value: {litwd48k_num_lits[litwd48k_num_lits[2] == 0].shape[0]}\")\n",
    "print(f\"Out of {litwd48k_num_lits.shape[0]} numerical literals => {litwd48k_num_lits[litwd48k_num_lits[2] == 0].shape[0] / litwd48k_num_lits.shape[0] * 100:.2f}%\")\n",
    "\n",
    "# Print the index of the numerical literals that have 0 as value\n",
    "print(litwd48k_num_lits[litwd48k_num_lits[2] == 0].index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T00:08:21.307582Z",
     "end_time": "2024-03-20T00:08:21.407450Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load LitWD48K vocab\n",
    "vocab_e1 = np.load(\"data/LitWD48K/vocab_e1\", allow_pickle=True)\n",
    "\n",
    "# Inspect the shape of the vocab\n",
    "print(len(vocab_e1))\n",
    "\n",
    "# Inspect the 4 list elements of the vocab\n",
    "print(vocab_e1[3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T00:10:43.206438Z",
     "end_time": "2024-03-20T00:10:43.234355Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def load_literals_and_attr_relations_num(self):\n",
    "    # with E = number of embeddings, R = number of attributive relations, V = feature dim\n",
    "    print('Start loading numerical literals: E x R')\n",
    "    attr_relations_num_unique = list(self.df_literals_num[1].unique())\n",
    "\n",
    "    print(\"Unique numerical attributive relations: \", len(attr_relations_num_unique))\n",
    "\n",
    "    attr_relation_num_2_id = {attr_relations_num_unique[i]: i for i in range(len(attr_relations_num_unique))}\n",
    "\n",
    "    # Map entities to ids\n",
    "    # Drop all literals that have entities that are not in the training set\n",
    "    self.df_literals_num = self.df_literals_num[self.df_literals_num[0].isin(self.entity2id.keys())]\n",
    "    self.df_literals_num[0] = self.df_literals_num[0].map(self.entity2id).astype(int)\n",
    "    # Map attributive relations to ids\n",
    "    self.df_literals_num[1] = self.df_literals_num[1].map(attr_relation_num_2_id).astype(int)\n",
    "    # Change literal values to float\n",
    "    self.df_literals_num[2] = self.df_literals_num[2].astype(float)\n",
    "\n",
    "    # Extract numerical literal feature vectors for each entity for literal values and attributive relations\n",
    "    features_num = []\n",
    "    features_num_attr = []\n",
    "    for i in tqdm(range(len(self.entities) + 2)):\n",
    "        df_i = self.df_literals_num[self.df_literals_num[0] == i]\n",
    "\n",
    "        feature_i = torch.zeros(len(attr_relations_num_unique))\n",
    "        feature_i_attr = torch.zeros(len(attr_relations_num_unique))\n",
    "        for index, row in df_i.iterrows():\n",
    "            # Numerical literal values: row[1] = attributive relation index, row[2] = literal value as float\n",
    "            feature_i[int(row[1])] = float(row[2])\n",
    "\n",
    "            # One-hot encoding for attributive relations\n",
    "            feature_i_attr[int(row[1])] = 1\n",
    "\n",
    "        features_num.append(feature_i)\n",
    "        features_num_attr.append(feature_i_attr)\n",
    "    features_num = torch.stack(features_num)\n",
    "    features_num_attr = torch.stack(features_num_attr)\n",
    "\n",
    "    # Normalize numerical literals and attributive relations\n",
    "    max_lit, min_lit = torch.max(features_num, dim=0).values, torch.min(features_num, dim=0).values\n",
    "    features_num = (features_num - min_lit) / (max_lit - min_lit + 1e-8)\n",
    "    features_num_attr -= features_num_attr.mean(dim=0, keepdim=True)\n",
    "\n",
    "    return features_num, features_num_attr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T00:12:59.684984Z",
     "end_time": "2024-03-20T00:12:59.694179Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
